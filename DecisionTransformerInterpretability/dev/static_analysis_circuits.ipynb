{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Analysis\n",
    "\n",
    "Attempt to do easy static stuff here with more complex stuff happening in the app. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import torch \n",
    "import json \n",
    "from IPython.display import display, HTML\n",
    "from src.decision_transformer.utils import (\n",
    "    load_decision_transformer,\n",
    "    # get_max_len_from_model_type,\n",
    ")\n",
    "from src.environments.registration import register_envs\n",
    "from src.environments.environments import make_env\n",
    "\n",
    "register_envs()\n",
    "\n",
    "from src.config import EnvironmentConfig\n",
    "\n",
    "model_path = \"../models/MiniGrid-MemoryS7FixedStart-v0/WorkingModel.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "env_config = state_dict[\"environment_config\"]\n",
    "env_config = EnvironmentConfig(**json.loads(env_config))\n",
    "\n",
    "env = make_env(env_config, seed=4200, idx=0, run_name=\"dev\")\n",
    "env = env()\n",
    "\n",
    "dt = load_decision_transformer(\n",
    "    model_path, env, tlens_weight_processing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_long_data_frame(tensor_result, dimension_names):\n",
    "    assert len(tensor_result.shape) == len(\n",
    "        dimension_names\n",
    "    ), \"The number of dimension names must match the number of dimensions in the tensor\"\n",
    "\n",
    "    tensor_2d = tensor_result.reshape(-1)\n",
    "    df = pd.DataFrame(tensor_2d.detach().numpy(), columns=[\"Score\"])\n",
    "\n",
    "    indices = pd.MultiIndex.from_tuples(\n",
    "        list(np.ndindex(tensor_result.shape)),\n",
    "        names=dimension_names,\n",
    "    )\n",
    "    df.index = indices\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_row_names_from_index_labels(names, index_labels):\n",
    "    indices = list(itertools.product(*index_labels))\n",
    "    multi_index = pd.MultiIndex.from_tuples(\n",
    "        indices,\n",
    "        names=names,  # use labels differently if we have index labels\n",
    "    )\n",
    "    if len(names) == 3:\n",
    "        multi_index = multi_index.to_series().apply(\n",
    "            lambda x: \"{0}, ({1},{2})\".format(*x)\n",
    "        )\n",
    "\n",
    "    elif names == 2:\n",
    "        multi_index = multi_index.to_series().apply(\n",
    "            lambda x: \"({0},{1})\".format(*x)\n",
    "        )\n",
    "    else:\n",
    "        raise (\"Index labels must be 2 or 3 dimensional\")\n",
    "\n",
    "    return multi_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get Components\n",
    "mlp0_in = dt.transformer.blocks[0].mlp.W_in.T.detach()\n",
    "mlp1_in = dt.transformer.blocks[1].mlp.W_in.T.detach()\n",
    "mlp2_in = dt.transformer.blocks[2].mlp.W_in.T.detach()\n",
    "\n",
    "mlp0_in_bias = dt.transformer.blocks[0].mlp.b_in.detach()\n",
    "mlp1_in_bias = dt.transformer.blocks[1].mlp.b_in.detach()\n",
    "mlp2_in_bias = dt.transformer.blocks[2].mlp.b_in.detach()\n",
    "\n",
    "mlp0_out = dt.transformer.blocks[0].mlp.W_out.detach()\n",
    "mlp1_out = dt.transformer.blocks[1].mlp.W_out.detach()\n",
    "mlp2_out = dt.transformer.blocks[2].mlp.W_out.detach()\n",
    "\n",
    "\n",
    "# stack the heads\n",
    "W_V = dt.transformer.W_V.detach()\n",
    "W_O = dt.transformer.W_O.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Head Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner OV circuits.\n",
    "W_OV = torch.einsum(\"lhmd,lhdn->lhmn\", W_V, W_O)\n",
    "print(W_OV.shape) # for each layer/head we have a mapping of in vectors to out vectors\n",
    "\n",
    "# Unembedding Values\n",
    "W_U = dt.action_predictor.weight\n",
    "W_U = W_U.detach()\n",
    "print(W_U.shape)\n",
    "\n",
    "\n",
    "U, S, V = torch.linalg.svd(W_OV)\n",
    "print(U.shape, S.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = V @ W_U.T # this is the final circuit\n",
    "projection.shape # for each layer/head we have a mapping to \"out vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead we projectect onto W_in from MLP?\n",
    "W_in = mlp2_in # calculate the projection matrix\n",
    "# W_in = mlp2_in / np.linalg.norm(mlp2_in, axis=1)[:, None] # normalize by the norm of the output vectors\n",
    "\n",
    "U, S, V = torch.linalg.svd(W_OV)\n",
    "# V = dt.transformer.ln_final(V) # layernorm\n",
    "\n",
    "projection = V @ W_in.T # this is the final circuit\n",
    "projection.shape # for each layer/head we have a mapping to \"out vectors\"\n",
    "\n",
    "# note layernorm might be worth applying, ignore for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V[0,0].norm(dim=0) # this is the norm of the first head of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dt.transformer.ln_final(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we know the rank is much smaller so let's just take the first 32 svd \n",
    "projection = projection[:,:,0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's flatten this so we can make easier sense of it. \n",
    "ov_mlp_in_congruence = tensor_to_long_data_frame(projection, [\"layer\", \"head\", \"head_right_svd\", \"neuron\"])\n",
    "# rename heads to L{Layer}H{head}\n",
    "ov_mlp_in_congruence[\"head\"] = ov_mlp_in_congruence[\"head\"].astype(str)\n",
    "ov_mlp_in_congruence[\"layer\"] = ov_mlp_in_congruence[\"layer\"].astype(str)\n",
    "ov_mlp_in_congruence[\"head\"] = ov_mlp_in_congruence.apply(lambda x: \"L{0}H{1}\".format(*x), axis=1)\n",
    "\n",
    "#Let's do the same thing for Neurons\n",
    "ov_mlp_in_congruence[\"neuron\"] = \"L2N\" + ov_mlp_in_congruence[\"neuron\"].astype(str)\n",
    "\n",
    "print(ov_mlp_in_congruence.shape)\n",
    "ov_mlp_in_congruence.head() # length 3*8*32*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_mlp_in_congruence.Score.describe(percentiles=[0.001, 0.01, 0.25, 0.5, 0.95, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's visualize this.\n",
    "import plotly.express as px\n",
    "fig = px.ecdf(ov_mlp_in_congruence, x=\"Score\")\n",
    "# make plot smaller\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=500,\n",
    "    height=300,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(ov_mlp_in_congruence.sort_values(\"Score\").head(30))\n",
    "ov_mlp_in_congruence[ov_mlp_in_congruence.Score < -0.277].neuron.value_counts()\n",
    "# ov_mlp_in_congruence[ov_mlp_in_congruence.Score < -6.043009].neuron.value_counts()\n",
    "ov_mlp_in_congruence[ov_mlp_in_congruence.Score > 0.286078].neuron.value_counts()\n",
    "# ov_mlp_in_congruence[ov_mlp_in_congruence.Score > 6.0975].neuron.value_counts()\n",
    "# ov_mlp_in_congruence.sort_values(\"Score\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's draw 768 random edges and calculate how many are above the 99.9th percentile or below the 0.1th percentile, do this 100 times and average.\n",
    "scores = ov_mlp_in_congruence.sample(768).Score.values\n",
    "print(np.mean(scores > 0.380826)*768)\n",
    "# print(np.mean(scores > 0.380826)*768)\n",
    "# print(np.mean(scores > 6.0975)*768)\n",
    "print(np.mean(scores < -0.377494)*768)\n",
    "# print(np.mean(scores < -0.377494)*7รท68)\n",
    "# print(np.mean(scores < -6.043009)*768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "tmp = ov_mlp_in_congruence[ov_mlp_in_congruence[\"head\"].isin(heads)]\n",
    "px.strip(\n",
    "    tmp,\n",
    "    # x=\"neuron\",\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    hover_data=[\"neuron\", \"head\", \"head_right_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n",
    "\n",
    "# display(tmp.sort_values(\"Score\").head(5))\n",
    "# ov_mlp_in_congruence.query(\"head == @head and layer == @layer\").sort_values(\"Score\").tail(5)\n",
    "\n",
    "# make a table with the top 5 neurons for each head\n",
    "top_neurons = tmp.groupby([\"head\", \"layer\"]).apply(lambda x: x.sort_values(\"Score\").tail(5))\n",
    "top_neurons = top_neurons.reset_index(drop=True)\n",
    "# top_neurons\n",
    "\n",
    "bottom_neurons = tmp.groupby([\"head\", \"layer\"]).apply(lambda x: x.sort_values(\"Score\").head(5))\n",
    "bottom_neurons = bottom_neurons.reset_index(drop=True)\n",
    "\n",
    "# bottom_neurons\n",
    "\n",
    "# concatenate them\n",
    "top_neurons = pd.concat([top_neurons, bottom_neurons])\n",
    "\n",
    "# get top connections by aggregatating any head / head_right svd. List the neurons and the scores\n",
    "top_connections = top_neurons.groupby([\"head\", \"head_right_svd\"]).apply(lambda x: x.sort_values(\"Score\"))\n",
    "top_connections.drop([\"head\", \"head_right_svd\", \"layer\"], axis=1, inplace=True)\n",
    "# top_connections = top_connections.reset_index(drop=True)\n",
    "top_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_connections.query(\"head == 'L1H0'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list neurons by heads/head_right_svd\n",
    "top_connections.reset_index().drop(\"level_2\", axis=1).groupby([\"head\", \"head_right_svd\"]).apply(lambda x: x[\"neuron\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list heads/head_right_svd by neuron\n",
    "top_connections.reset_index().drop(\"level_2\", axis=1).groupby([\"neuron\"]).apply(lambda x: x[[\"head\", \"head_right_svd\"]].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons= [108, 204, 1, 4, 235, 79, 63, 132, 169, 255, 151]\n",
    "neurons= [f\"L2N{n}\" for n in neurons]\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "tmp = ov_mlp_in_congruence.copy()\n",
    "# tmp = tmp[tmp[\"head\"].isin(heads)]\n",
    "tmp[\"in_candidate_heads\"] = tmp[\"head\"].isin(heads)\n",
    "tmp[\"in_top_5_svd\"] = tmp[\"head_right_svd\"] < 6\n",
    "tmp = tmp[tmp[\"neuron\"].isin(neurons)]\n",
    "# tmp = tmp[tmp[\"head_right_svd\"] < 6]\n",
    "# tmp = tmp.sort_values(\"neuron\")\n",
    "px.strip(\n",
    "    tmp,\n",
    "    x=\"neuron\",\n",
    "    y=\"Score\",\n",
    "    color=\"neuron\",\n",
    "    hover_data=[\"neuron\", \"head\", \"head_right_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons= [108, 204, 1, 4, 235, 79, 63, 132, 169, 255, 151]\n",
    "neurons= [f\"L2N{n}\" for n in neurons]\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "tmp = ov_mlp_in_congruence.copy()\n",
    "# tmp = tmp[tmp[\"head\"].isin(heads)]\n",
    "# tmp[\"in_candidate_heads\"] = tmp[\"head\"].isin(heads)\n",
    "# tmp[\"in_top_5_svd\"] = tmp[\"head_right_svd\"] < 6\n",
    "tmp = tmp[tmp[\"neuron\"] == \"L2N108\"]\n",
    "# tmp = tmp[tmp[\"head_right_svd\"] < 6]\n",
    "# tmp = tmp.sort_values(\"neuron\")\n",
    "px.strip(\n",
    "    tmp,\n",
    "    x=\"neuron\",\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    hover_data=[\"neuron\", \"head\", \"head_right_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons= [108, 204, 1, 4, 235, 79, 63, 132, 169, 255, 151]\n",
    "neurons= [f\"L2N{n}\" for n in neurons]\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "tmp = ov_mlp_in_congruence.copy()\n",
    "tmp[\"Score\"] = tmp[\"Score\"].abs()\n",
    "# group by neurons and heads and calculate the average score\n",
    "tmp = tmp.groupby([\"neuron\", \"head\"]).Score.mean().reset_index()\n",
    "tmp['candidate_head'] = tmp[\"head\"].isin(heads)\n",
    "# tmp\n",
    "fig = px.ecdf(tmp, x = \"Score\", color = \"neuron\")\n",
    "fig.show()\n",
    "\n",
    "px.strip(\n",
    "    tmp[tmp.neuron.isin(neurons)],\n",
    "    x=\"neuron\",\n",
    "    y=\"Score\",\n",
    "    color=\"candidate_head\",\n",
    "    hover_data=[\"neuron\", \"head\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons= [108, 204, 1, 4, 235, 79, 63, 132, 169, 255, 151]\n",
    "neurons= [f\"L2N{n}\" for n in neurons]\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "tmp = ov_mlp_in_congruence.copy()\n",
    "tmp[\"Score\"] = tmp[\"Score\"].abs()\n",
    "# replace \"Score\" with rank in entire dataset\n",
    "# tmp[\"Score\"] = tmp[\"Score\"].rank().astype(int)\n",
    "\n",
    "# filter by heads and neurons\n",
    "tmp = tmp[tmp[\"head\"].isin(heads)]\n",
    "tmp = tmp[tmp[\"neuron\"].isin(neurons)]\n",
    "\n",
    "# aggregate by head/neuron and take the max score\n",
    "tmp = tmp.groupby([\"neuron\", \"head\"]).Score.max().reset_index()\n",
    "# pivote the table\n",
    "tmp = tmp.pivot(index=\"neuron\", columns=\"head\", values=\"Score\")\n",
    "# color the table\n",
    "tmp.style.background_gradient(cmap=\"Blues\", vmin =0, vmax = 0.524874)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a graph. \n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "neurons= [108, 204, 1, 4, 235, 79, 63, 132, 169, 255, 151]\n",
    "neurons = [f\"L2N{n}\" for n in neurons]\n",
    "\n",
    "ov_mlp_in_congruence[\"head_direction\"] = ov_mlp_in_congruence[\"head\"] + \" -> \" + ov_mlp_in_congruence[\"head_right_svd\"].astype(str)\n",
    "\n",
    "# now let's do some arbitrary filtering: \n",
    "tmp = ov_mlp_in_congruence.copy()\n",
    "\n",
    "# filter by heads and neurons\n",
    "tmp = tmp[tmp[\"head\"].isin(heads)]\n",
    "tmp = tmp[tmp[\"neuron\"].isin(neurons)]\n",
    "\n",
    "# get 0.01% and 99.99% quantiles for scores in general and filter by them\n",
    "q = tmp[\"Score\"].quantile([0.01, 0.99])\n",
    "tmp = tmp[(tmp[\"Score\"] < q[0.01]) | (tmp[\"Score\"] > q[0.99])]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "from pyvis.network import Network\n",
    "\n",
    "# create a graph\n",
    "G = nx.from_pandas_edgelist(tmp, source=\"head_direction\", target=\"neuron\", edge_attr=\"Score\")\n",
    "\n",
    "# print out the number of disconnected components\n",
    "# add colors, wed anderson pallette\n",
    "color_head_map = {\n",
    "    \"L0H0\": \"#2A9D8F\",\n",
    "    \"L0H4\": \"#E9C46A\",\n",
    "    \"L1H0\": \"#F4A261\",\n",
    "    \"L2H1\": \"#E76F51\",\n",
    "}\n",
    "\n",
    "\n",
    "# # create a pyvis network\n",
    "nt = Network(\"1000px\", \"2000px\", notebook=True, bgcolor=\"#222222\", font_color=\"white\")\n",
    "nt.from_nx(G)\n",
    "nt.show(\"tmp.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heads SVD to Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For completeness, I also want to see SVD's for heads directly writing to outputs \n",
    "\n",
    "unembed_projection = V @ W_U.T # this is the final circuit\n",
    "unembed_projection.shape # for each layer/head we have a mapping to \"out vectors\"\n",
    "unembed_projection = unembed_projection[:,:,0:32]\n",
    "ov_unembed_congruence = tensor_to_long_data_frame(unembed_projection, [\"layer\", \"head\", \"head_right_svd\", \"Action\"])\n",
    "# rename heads to L{Layer}H{head}\n",
    "ov_unembed_congruence[\"head\"] = ov_unembed_congruence[\"head\"].astype(str)\n",
    "ov_unembed_congruence[\"layer\"] = ov_unembed_congruence[\"layer\"].astype(str)\n",
    "ov_unembed_congruence[\"head\"] = ov_unembed_congruence.apply(lambda x: \"L{0}H{1}\".format(*x), axis=1)\n",
    "\n",
    "display(ov_unembed_congruence.head())\n",
    "ov_unembed_congruence.Score.describe(percentiles=[0.001, 0.01, 0.25, 0.5, 0.95, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "# tmp = ov_mlp_in_congruence[ov_mlp_in_congruence[\"head\"].isin(heads)]\n",
    "px.strip(ov_unembed_congruence,\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    hover_data=[\"Action\", \"head\", \"head_right_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert long to wide (score for each action, head, head_right_svd\n",
    "from src.streamlit_app.constants import ACTION_NAMES\n",
    "\n",
    "# ov_unembed_congruence[\"Action\"] = ov_unembed_congruence[\"Action\"].apply(lambda x: ACTION_NAMES[x])\n",
    "ov_unembed_congruence_wide = ov_unembed_congruence.pivot(index=[\"layer\", \"head\", \"head_right_svd\"], columns=\"Action\", values=\"Score\")\n",
    "#reset column index\n",
    "ov_unembed_congruence_wide.reset_index(inplace=True)\n",
    "# set opacity column to be 1 - head_right_svd / 32\n",
    "ov_unembed_congruence_wide[\"opacity\"] = 1 - ov_unembed_congruence_wide[\"head_right_svd\"] / 32\n",
    "ov_unembed_congruence_wide.opacity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # scatter plot left vs right scores\n",
    "fig = px.scatter(\n",
    "    ov_unembed_congruence_wide,\n",
    "    y=\"left\",\n",
    "    x=\"right\",\n",
    "    color=\"head\",\n",
    "    opacity= ov_unembed_congruence_wide[\"opacity\"],\n",
    "    hover_data=[\"head\", \"head_right_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "# get max abs value in either left or right\n",
    "max_abs = np.max(np.abs(ov_unembed_congruence_wide[[\"left\", \"right\"]].values))+0.05\n",
    "# set the range\n",
    "fig.update_layout(xaxis=dict(range=[-max_abs, max_abs]), yaxis=dict(range=[-max_abs, max_abs]))\n",
    "# fig.update_layout(xaxis=dict(aspectmode='equal'), yaxis=dict(aspectmode='equal'))\n",
    "# add dotted grey y=x line\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=-max_abs,\n",
    "    y0=-max_abs,\n",
    "    x1=max_abs,\n",
    "    y1=max_abs,\n",
    "    line=dict(\n",
    "        color=\"Grey\",\n",
    "        width=1,\n",
    "        dash=\"dot\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Observations into Heads SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels. \n",
    "from src.streamlit_app.constants import SPARSE_CHANNEL_NAMES\n",
    "import itertools \n",
    "\n",
    "all_index_labels = [\n",
    "    SPARSE_CHANNEL_NAMES,\n",
    "    list(range(7)),\n",
    "    list(range(7)),\n",
    "]\n",
    "indices = list(itertools.product(*all_index_labels))\n",
    "index_labels = [\"{0}, ({1},{2})\".format(*index) for index in indices]\n",
    "print(index_labels[:4])\n",
    "\n",
    "# extract just the channels\n",
    "channel_labels = [label.split(\",\")[0] for label in index_labels]\n",
    "print(channel_labels[:4])\n",
    "\n",
    "embedding = dt.state_embedding.weight.detach().T\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can get the cossine similarity matrix. but first let's filter for the channels we care about\n",
    "channels_we_care_about = [\"key\", \"ball\", \"unseen\", \"empty\", \"green\", \"grey\", \"red\"]\n",
    "index_mask = [label in channels_we_care_about for label in channel_labels]\n",
    "print(sum(index_mask)) # 7*7*7 = 343 channels\n",
    "\n",
    "restricted_embeddings = embedding[index_mask]\n",
    "restricted_labels = [label for label, mask in zip(index_labels, index_mask) if mask]\n",
    "print(restricted_embeddings.shape)\n",
    "print(len(restricted_labels))\n",
    "\n",
    "restricted_embeddings = restricted_embeddings / np.linalg.norm(restricted_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if instead we projectect onto W_in from MLP?\n",
    "# W_in = mlp2_in # calculate the projection matrix\n",
    "# # W_in = mlp2_in / np.linalg.norm(mlp2_in, axis=1)[:, None] # normalize by the norm of the output vectors\n",
    "\n",
    "U, S, V = torch.linalg.svd(W_OV)\n",
    "# V = dt.transformer.ln_final(V) # layernorm\n",
    "U = U[:, :, 0:32] # only keep the first 32 singular values\n",
    "\n",
    "projection = U @ restricted_embeddings.T  # this is the final circuit\n",
    "projection.shape # for each layer/head we have a mapping to \"out vectors\"\n",
    "\n",
    "# # note layernorm might be worth applying, ignore for now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_embedding_congruence = tensor_to_long_data_frame(projection, [\"layer\", \"head\", \"head_left_svd\", \"embedding\"])\n",
    "\n",
    "# rename embedding dimensions restricted labels\n",
    "ov_embedding_congruence[\"embedding\"] = ov_embedding_congruence[\"embedding\"].map(dict(zip(range(len(restricted_labels)), restricted_labels)))\n",
    "\n",
    "# do the whole head/layer rename thingo\n",
    "ov_embedding_congruence[\"head\"] = ov_embedding_congruence[\"head\"].astype(str)\n",
    "ov_embedding_congruence[\"head\"] = ov_embedding_congruence.apply(lambda x: \"L{0}H{1}\".format(*x), axis=1)\n",
    "# drop layer now\n",
    "ov_embedding_congruence.drop(columns=[\"layer\"], inplace=True)\n",
    "\n",
    "display(ov_embedding_congruence.Score.describe(percentiles=[0.001, 0.01, 0.25, 0.5, 0.95, 0.99, 0.999]))\n",
    "ov_embedding_congruence # shape 3*8*256*343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ov_embedding_congruence.Score.describe(percentiles=[0.001, 0.01, 0.25, 0.5, 0.95, 0.99, 0.999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px \n",
    "\n",
    "# heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "px.strip(\n",
    "    ov_embedding_congruence.query(\"embedding == 'ball, (2,6)' or embedding == 'key, (2,6)'\"),\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    x=\"head\",\n",
    "    facet_col=\"embedding\",\n",
    "    hover_data=[\"embedding\", \"head\", \"head_left_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ov_embedding_congruence.query(\"embedding == 'key, (1,2)' or embedding == 'key, (5,2)' or embedding == 'ball, (1,2)' or embedding == 'ball, (5,2)'\")\n",
    "px.strip(\n",
    "    tmp,\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    x=\"head\",\n",
    "    facet_col=\"embedding\",\n",
    "    hover_data=[\"embedding\", \"head\", \"head_left_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ov_embedding_congruence.query(\"embedding == 'key, (1,6)' or embedding == 'key, (5,6)' or embedding == 'ball, (1,6)' or embedding == 'ball, (5,6)'\")\n",
    "px.strip(\n",
    "    tmp,\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    x=\"head\",\n",
    "    facet_col=\"embedding\",\n",
    "    hover_data=[\"embedding\", \"head\", \"head_left_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "heads = [\"L0H0\", \"L0H4\", \"L1H0\", \"L2H1\"]\n",
    "px.strip(\n",
    "    ov_embedding_congruence[ov_embedding_congruence[\"head\"].isin(heads)],\n",
    "    y=\"Score\",\n",
    "    color=\"head\",\n",
    "    x=\"head\",\n",
    "    hover_data=[\"embedding\", \"head\", \"head_left_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [f\"L0H{i}\" for i in range(8)]\n",
    "px.strip(\n",
    "    ov_embedding_congruence[ov_embedding_congruence[\"head\"].isin(heads)],\n",
    "    y=\"Score\",\n",
    "    color=ov_embedding_congruence[ov_embedding_congruence[\"head\"].isin(heads)].embedding.str.contains(\"ball, (2,6)\", regex=False),\n",
    "    x=\"head\",\n",
    "    hover_data=[\"embedding\", \"head\", \"head_left_svd\"],\n",
    "    template=\"plotly_dark\",\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ov_embedding_congruence#[ov_embedding_congruence[\"head\"].isin(heads)]\n",
    "\n",
    "# make a table with the top 5 embedding for each head\n",
    "top_embeddings = tmp.groupby([\"head\"]).apply(lambda x: x.sort_values(\"Score\").tail(5))\n",
    "top_embeddings = top_embeddings.reset_index(drop=True)\n",
    "# top_neurons\n",
    "\n",
    "bottom_embeddings = tmp.groupby([\"head\"]).apply(lambda x: x.sort_values(\"Score\").head(5))\n",
    "bottom_embeddings = bottom_embeddings.reset_index(drop=True)\n",
    "\n",
    "# bottom_neurons\n",
    "\n",
    "# concatenate them\n",
    "top_embeddings = pd.concat([top_embeddings, bottom_embeddings])\n",
    "\n",
    "# get top connections by aggregatating any head / head_right svd. List the neurons and the scores\n",
    "top_connections = top_embeddings.groupby([\"head\", \"head_left_svd\"]).apply(lambda x: x.sort_values(\"Score\"))\n",
    "top_connections.drop([\"head\", \"head_left_svd\"], axis=1, inplace=True)\n",
    "# top_connections = top_connections.reset_index(drop=True)\n",
    "top_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(top_connections.reset_index().embedding.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_connections.reset_index().drop(\"level_2\", axis=1).groupby([\"head\", \"head_left_svd\"]).apply(lambda x: x[\"embedding\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_connections.reset_index().drop(\"level_2\", axis=1).groupby([\"embedding\"]).apply(lambda x: x[[\"head\", \"head_left_svd\"]].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing in to out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If SVD works then the corresponding/in outs of at least neurons in layer L0H0 should make sense?\n",
    "\n",
    "display(ov_embedding_congruence.query(\"head == 'L0H0' and head_left_svd == 1\").sort_values(\"Score\", ascending=False).head(10))\n",
    "display(ov_embedding_congruence.query(\"head == 'L0H0' and head_left_svd == 1\").sort_values(\"Score\", ascending=False).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ov_embedding_congruence.query(\"head == 'L1H0' and head_left_svd == 1\").sort_values(\"Score\", ascending=False).head(10))\n",
    "display(ov_embedding_congruence.query(\"head == 'L1H0' and head_left_svd == 1\").sort_values(\"Score\", ascending=False).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ov_embedding_congruence.query(\"head == 'L1H0' and head_left_svd == 1\").sort_values(\"Score\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # let's flatten this so we can make easier sense of it. \n",
    "# ov_mlp_in_congruence = tensor_to_long_data_frame(projection, [\"layer\", \"head\", \"head_right_svd\", \"neuron\"])\n",
    "# # rename heads to L{Layer}H{head}\n",
    "# ov_mlp_in_congruence[\"head\"] = ov_mlp_in_congruence[\"head\"].astype(str)\n",
    "# ov_mlp_in_congruence[\"layer\"] = ov_mlp_in_congruence[\"layer\"].astype(str)\n",
    "# ov_mlp_in_congruence[\"head\"] = ov_mlp_in_congruence.apply(lambda x: \"L{0}H{1}\".format(*x), axis=1)\n",
    "\n",
    "# #Let's do the same thing for Neurons\n",
    "# ov_mlp_in_congruence[\"neuron\"] = \"L2N\" + ov_mlp_in_congruence[\"neuron\"].astype(str)\n",
    "\n",
    "# print(ov_mlp_in_congruence.shape)\n",
    "# ov_mlp_in_congruence.head() # length 3*8*32*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# get cosine similarity of OV vectors with themselves\n",
    "\n",
    "w_OV_similarity = F.cosine_similarity(W_OV, W_OV, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 256])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_OV_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_transformer_interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
